model_name: "Judge_Model"

backend:
  backend_module: "vllm"  # vllm | openai
  vllm:
    model: ""
    tokenizer: null
    dtype: "auto"
    num_devices: 1
    tensor_parallel_size: 1
    max_model_length: null
    gpu_memory_utilization: 0.9
    trust_remote_code: true
    enforce_eager: false
    device: "auto"
  openai:
    model: ""
    api_key: null
    base_url: null

sampling_params:
  temperature: 0.7
  top_p: 0.95
  top_k: -1
  max_tokens: 2048
