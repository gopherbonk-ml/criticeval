- evaluation.mode=all
- paths.data_dir=data
- paths.save_dir=outputs
- data.problem_file=problems_example.csv
- outputs.experiment_id=example_run
- outputs.save_solver_outputs=True
- template.solver_templates=[base_solver]
- template.judger_templates=[base_judger]
- template.use_extract_answer_for_solver=True
- template.use_extract_answer_for_judger=True
- template.extract_answer_func_for_solver=boxed_answer_extractor
- template.extract_answer_func_for_judger=boxed_answer_extractor
- solver.backend.backend_module=vllm
- solver.backend.device=npu
- solver.backend.num_workers=8
- solver.backend.num_device_per_worker=2
- solver.backend.vllm.backend=vllm_npu
- solver.backend.device=npu
- solver.backend.num_workers=8
- solver.backend.num_device_per_worker=4
- solver.backend.vllm.model=/workspace/local/models/Qwen2.5-VL-3B-Instruct
- solver.backend.vllm.dtype=auto
- solver.backend.vllm.device=npu
- solver.backend.vllm.tensor_parallel_size=2
- solver.backend.vllm.max_model_length=8192
- solver.backend.vllm.gpu_memory_utilization=0.6
- solver.backend.vllm.trust_remote_code=True
- solver.backend.vllm.enforce_eager=True
- solver.sampling_params.temperature=0
- solver.sampling_params.max_tokens=4096
- solver.sampling_params.top_p=0.9
- judger.backend.backend_module=vllm
- judger.backend.vllm.backend=vllm_npu
- judger.backend.vllm.model=/workspace/local/models/Qwen2.5-VL-3B-Instruct
- judger.backend.vllm.dtype=auto
- judger.backend.vllm.device=npu
- judger.backend.vllm.tensor_parallel_size=4
- judger.backend.vllm.max_model_length=8192
- judger.backend.vllm.gpu_memory_utilization=0.6
- judger.backend.vllm.trust_remote_code=True
- judger.backend.vllm.enforce_eager=True
- judger.sampling_params.temperature=0.6
- judger.sampling_params.max_tokens=4096
- judger.sampling_params.top_p=0.9
